{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Course**: Data Visualization (Prof. Dr. Heike Leitte, Luisa Vollmer, RPTU Kaiserslautern),   **Name**: XXX XXX,   **Date**: DD.MM.YYYY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "    \n",
    "# Assignment 4 - Principal Component Analysis (PCA)\n",
    "</div>\n",
    "\n",
    "\n",
    "### Outline and goals\n",
    "\n",
    "In the fourth assignment, we will explore a cars dataset using principal component analysis. Each car is described by 25 variables. The dataset contains six types of cars and we would like to understand how they are different. The goal of this assignment is that you are able to:\n",
    "- explore high-dimensional data with many variables\n",
    "- compute and interpret PCA\n",
    "- charactize groups in the PCA plot\n",
    "- find patterns and outliers in data with many variables\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "\n",
    "**Important**: While no points will be awarded for typing the correct answers in the notebooks, it is highly advised to solve the tasks thoroughly. They are designed to be encouraging and provide you with valuable learnings for the exam, understanding of the methods and practical coding.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "All tasks in this notebook are marked in green.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from bokeh.models import ColumnDataSource, ColorBar, LinearColorMapper, CategoricalColorMapper\n",
    "from bokeh.models import Arrow, NormalHead, LabelSet, Label\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.palettes import Category10, Category20, Viridis\n",
    "from bokeh.transform import factor_cmap, linear_cmap\n",
    "from bokeh.io import export_png\n",
    "from bokeh.layouts import gridplot, row\n",
    "from bokeh.core.properties import value\n",
    "from bokeh.models.tickers import FixedTicker\n",
    "\n",
    "from math import pi\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## 1. Load the 1993 cars dataset\n",
    "</div>\n",
    "\n",
    "First, we load the data and handle missing values. We ignore the variable LUGGAGE CAPACITY which has no information for vans and some missing values. We also drop two cars with missing values.\n",
    "\n",
    "Description of variables:\n",
    "- Manufacturer\n",
    "- Model\n",
    "- Type: Small, Sporty, Compact, Midsize, Large, Van\n",
    "- Minimum Price (in \\$1,000) - Price for basic version of this model\n",
    "- Midrange Price (in \\$1,000) - Average of Min and Max prices\n",
    "- Maximum Price (in \\$1,000) - Price for a premium version\n",
    "- City MPG (miles per gallon by EPA rating)\n",
    "- Highway MPG\n",
    "- Air Bags standard 0 = none, 1 = driver only, 2 = driver & passenger\n",
    "- Drive train type 0 = rear wheel drive 1 = front wheel drive 2 = all wheel drive\n",
    "- Number of cylinders\n",
    "- Engine size (liters)\n",
    "- Horsepower (maximum)\n",
    "- RPM (revs per minute at maximum horsepower)\n",
    "- Engine revolutions per mile (in highest gear)\n",
    "- Manual transmission available 0 = No, 1 = Yes\n",
    "- Fuel tank capacity (gallons)\n",
    "- Passenger capacity (persons)\n",
    "- Length (inches)\n",
    "- Wheelbase (inches)\n",
    "- Width (inches)\n",
    "- U-turn space (feet)\n",
    "- Rear seat room (inches)\n",
    "- Luggage capacity (cu. ft.)\n",
    "- Weight (pounds)\n",
    "- Domestic? 0 = non-U.S. manufacturer 1 = U.S. manufacturer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "cars = pd.read_csv( '93cars.dat.csv', sep='\\s+', na_values='*')\n",
    "print(\"size of input dataframe\", cars.shape)\n",
    "\n",
    "\n",
    "# substitute missing values\n",
    "cars.drop(['LuggageCapacity'], axis=1, inplace=True)\n",
    "cars.dropna(inplace=True)\n",
    "cars.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"size after removing NaN\", cars.shape)\n",
    "print(\"variables in dataframe:\", list(cars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First render the entire data using seaborn and its scatterplot matrix function. This may take very long and you have a pdf-export in your folder. No need to run this code, unless you would like to see it in the notebook and try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# This could take a while\n",
    "# sns_plot = sns.pairplot(cars, hue=\"Type\")\n",
    "\n",
    "# uncomment to export plot\n",
    "#sns_plot.savefig(\"cars93_SPLOM.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## 2. Understand the variables\n",
    "</div>\n",
    "\n",
    "Each car is described by a long list of variables and analyzing them individually and pair-wise will take a long time. In this assignment we will first reduce the dimensionality of the dataset and then analyze it.\n",
    "\n",
    "### Explore scatterplot matrix\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "To understand the problem take a look at the scatterplot matrix provided in your data folder ([cars93_SPLOM.pdf](cars93_SPLOM.pdf)). What can you tell about small cars? (blue points, color legend is on the right) (no answer required and don't spend more than a few minutes)\n",
    "</div>\n",
    "\n",
    "### Explore correlation matrix\n",
    "\n",
    "Your first task is to find groups of variables that belong together and understand their connection.\n",
    "Therefore, we compute [linear correlation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html) as provided by pandas. As bokeh requires the input as a linear array, we also linearize the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Pearson correlation\n",
    "corr = cars.corr(method='pearson', numeric_only=True)\n",
    "variables = list(corr)\n",
    "\n",
    "# linearize the correlation matrix\n",
    "lin_corr = pd.melt(corr.assign(index=corr.index), id_vars=['index'])\n",
    "lin_corr['size'] = [abs(val)*17 for val in lin_corr.value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code renders a correlation matrix using bokeh. For each pair of variables, the correlation is represented by a colored square. Size and color encode the amount of linear correlation. Large red squares indicate strong positive correlation, large blue squares strong negative correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(x_range=variables, y_range=variables, width=800, height=700,\n",
    "           title=\"Correlation matrix\")\n",
    "\n",
    "p.square(source=lin_corr, x='index', y='variable', size='size', color=linear_cmap('value', 'RdYlBu7', -1, 1))\n",
    "\n",
    "color_bar = ColorBar(color_mapper=LinearColorMapper('RdYlBu5', low=-1, high=1),\n",
    "                     label_standoff=12, border_line_color=None, location=(0,0))\n",
    "p.add_layout(color_bar, 'right')\n",
    "\n",
    "p.xgrid.ticker = FixedTicker(ticks=list(range(1,len(corr))))\n",
    "p.ygrid.ticker = FixedTicker(ticks=list(range(1,len(corr))))\n",
    "p.xaxis.major_label_orientation = -pi/4\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Find groups of variables that are strongly correlated** (positive or negative). Each group consists of variables that are pair-wise strongly correlated. The example below shows the group \"Properties of the engine\" which consists of horsepower, engine, cylinders. \n",
    "    \n",
    "**Tasks**\n",
    "- Find three additional groups, name them, and list the variables that belong to them.\n",
    "- Analyze if these high-level groups are correlated: Locate the positions in the matrix that encode the correlations between elements from two groups. Can you detect patterns?\n",
    "- Validate your findings using the scatterplot matrix.\n",
    "</div>\n",
    "\n",
    "![](cars_corrMatrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Groups:\n",
    "- Engine properties: horsepower, engine, cylinders\n",
    "- Group2\n",
    "- Group3\n",
    "- ...\n",
    "\n",
    "Additional correlations between groups:\n",
    "- GX + GY\n",
    "- GY + GZ\n",
    "- ...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## 3. Explained variance of PCA\n",
    "</div>\n",
    "\n",
    "Compute the [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) for the cars dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use numeric attributes and exclude the type which we would like to predict\n",
    "var = ['MinPrice', 'MidPrice','MaxPrice', 'CityMpg', 'HighwayMpg', 'Cylinders',\n",
    "       'Engine', 'Horsepower', 'RPM', 'EngineRev',\n",
    "       'Tank', 'Passenger', 'Length', 'Width', 'UTurn', 'Weight']\n",
    "\n",
    "# store standardized data in cars_std\n",
    "cars_std = StandardScaler().fit_transform(cars[var])\n",
    "\n",
    "# store PCA in variable pca\n",
    "pca = PCA( n_components=len(var) ).fit(cars_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_exp = pca.explained_variance_ratio_*100\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "x = ['PC%s' %(i+1) for i in range(len(var))]\n",
    "\n",
    "source = ColumnDataSource( dict(x=x, var_exp=var_exp, cum_var_exp=cum_var_exp) )\n",
    "\n",
    "p = figure( width=520, height=400, toolbar_location=None, x_range=x, y_range=(-2,105),\n",
    "            title=\"Explained variance of PCA of cars dataset\")\n",
    "\n",
    "p.vbar( source=source, x='x', top='var_exp', width=0.9, bottom=0, legend_label='Explained variance' )\n",
    "\n",
    "p.circle( x, cum_var_exp, color='orange', size=5, legend_label=\"Cumulative explained variance\")\n",
    "p.line( x, cum_var_exp, color='orange', line_width=2 )\n",
    "\n",
    "p.legend.location = (235,155)\n",
    "p.legend.border_line_color = None\n",
    "p.xgrid.visible = False\n",
    "p.yaxis.axis_label = \"Explained variance in percent\"\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Questions**\n",
    "- How much variance is explained by the first two principal component(s) roughly?\n",
    "- How many components do you need to explain 90% of the variance in the data (roughly, use figure estimate)?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## 4. Interpret the projection\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project the data and add the labels using the cars' type\n",
    "pca_cars = pd.DataFrame( pca.transform(cars_std), columns=['PC%i' % (i+1) for i in range(pca.n_components_)])\n",
    "pca_cars['label'] = cars.Type\n",
    "\n",
    "# get the different classes in the Type variable\n",
    "factors = sorted(pca_cars.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(pca_cars)\n",
    "\n",
    "p = figure( width=600, height=600, y_range=(-4.5,4.8),\n",
    "            title=\"Projection onto first two principal components\")\n",
    "\n",
    "p.circle( source=source, x='PC1', y='PC2', size=9, legend_group='label',\n",
    "          color=factor_cmap('label', palette=Category10[10], factors=factors))\n",
    "p.xaxis.axis_label = 'PC1' \n",
    "p.yaxis.axis_label = 'PC2' \n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Explain the axes**\n",
    "\n",
    "The figure above shows the projected cars data. Explain the x- and y-axis. What can you tell about cars that are located on the left/right and what about cars at the top/bottom? \n",
    "</div>\n",
    "\n",
    "Hints:\n",
    "- You cannot solve the problem using the current chart only. You need some additional technique as explained in lecture.\n",
    "- The eigenvectors can be obtained through `pca.components_`\n",
    "- A biplot is most helpful for the upcoming questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Characterize small cars**\n",
    "\n",
    "You already tried to characterize small cars using the scatterplot matrix. Now do the same again using the PCA-plot and the analyses you made about the axes. What can you say about small cars? (small cars are red in this plot!)\n",
    "    \n",
    "Show a scatterplot using two informative variables to distinguish small cars from other cars.\n",
    "    \n",
    "Which cars are hard to distinguish from small cars?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**Distinguish large cars and vans**\n",
    "\n",
    "Show a scatterplot that makes it easy to distinguish between large cars and vans. Which two variables do you pick?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
